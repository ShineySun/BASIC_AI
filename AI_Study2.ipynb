{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Study2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShineySun/BASIC_AI/blob/master/AI_Study2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S8snkqy_El2",
        "colab_type": "text"
      },
      "source": [
        "#인공지능 study 2\n",
        "## 20143038 김선필\n",
        "###### 1. [영상 인식] 다음 코드를 무엇을 의미하는지 이해하고 실행하여 결과를 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5rMOfl8_AmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_1hI-6UAaZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "is_cuda = False\n",
        "# gpu 사용 여부 검사\n",
        "if torch.cuda.is_available():\n",
        "  is_cuda = True\n",
        "\n",
        "# Mnist 데이터를 정규화 (각 채널별)\n",
        "transformation = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
        "train_dataset = datasets.MNIST('data/',train = True, transform = transformation, download = True)\n",
        "test_dataset = datasets.MNIST('data/',train = False, transform = transformation, download = True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
        "# sample_data -> train_loader의 시작 데이터\n",
        "sample_data = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZgYSbVIApKY",
        "colab_type": "code",
        "outputId": "b62b2af6-9924-4723-8e62-b87c854ef42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# plot_img : 평균과 표준편차를 이용하여 이미지를 정규화 시키고 출력한다.\n",
        "def plot_img(image):\n",
        "  image = image.numpy()[0]\n",
        "  mean = 0.1307\n",
        "  std = 0.3081\n",
        "  image = ((mean*image) + std)\n",
        "  plt.imshow(image, cmap = 'gray')\n",
        "\n",
        "# 화면 출력 확인\n",
        "plot_img(sample_data[0][2]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsANBEHYgCMIOBEHYgSD+H1M0hgeucr8TAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsYm3cl0CbOE",
        "colab_type": "code",
        "outputId": "9aef7b39-955f-4e28-cc31-ddcff7a745af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# 화면 출력 확인\n",
        "plot_img(sample_data[0][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg4EQdiBIP4fNIaC93yX8HIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0wDB0AyC_lg",
        "colab_type": "code",
        "outputId": "0e3efd8e-aec6-49dd-e068-5adb12220aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# class definition\n",
        "class Net(nn.Module):\n",
        "  # 클래스 생성자\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # input : 1  output : 10  kernel : 5x5\n",
        "    self.conv1 = nn.Conv2d(1,10,kernel_size = 5)\n",
        "    # input : 10  output : 20  kernel : 5x5\n",
        "    self.conv2 = nn.Conv2d(10,20,kernel_size = 5)\n",
        "    # Dropout : 생성된 특징맵에서 필요한 것들만 보겠다. - overfitting 해결\n",
        "    # 디폴트 값의 확률의 드롭아웃을 만든다.\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "\n",
        "    # 선형 완전 연결층\n",
        "    # input : 320  output : 50\n",
        "    self.fc1 = nn.Linear(320,50)\n",
        "    # input : 50   output : 10\n",
        "    self.fc2 = nn.Linear(50,10)\n",
        "  \n",
        "  # 순전파\n",
        "  def forward(self,x):\n",
        "    # conv1 층 통과후 max pooling 하여 활성함수 relu를 통과 시킨다.\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "    # conv2 을 통과 후 드랍 아웃을 시킨다.\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
        "    x = x.view(-1,320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    # log softmax 함수를 통과 시킨 x 값을 반환한다.\n",
        "    return F.log_softmax(x,dim=1)\n",
        "\n",
        "model = Net()\n",
        "\n",
        "if is_cuda:\n",
        "  model.cuda()\n",
        "\n",
        "# 스토캐스틱 그레디언트 디센트 방법으로 최적화를 시킨다.\n",
        "# 학습률은 0.01 로 정해줬다.\n",
        "optimizer = optim.SGD(model.parameters(),lr = 0.01)\n",
        "\n",
        "data, target = next(iter(train_loader))\n",
        "# data를 모델에 통과 시킨다.\n",
        "output = model(Variable(data.cuda()))\n",
        "\n",
        "# output.size() 출력 확인\n",
        "print(output.size())\n",
        "\n",
        "# target.size() 출력 확인\n",
        "print(target.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCrePkVVhakg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss 와 accuracy를 계산하여 반환하는 함수\n",
        "def fit(epoch, model, data_loader, phase = 'training', volatile = False):\n",
        "  if phase == 'training':\n",
        "    model.train()\n",
        "  if phase == 'validation':\n",
        "    model.eval()\n",
        "    volatile = True\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  running_correct = 0\n",
        "\n",
        "  for batch_idx, (data,target) in enumerate(data_loader):\n",
        "    if is_cuda:\n",
        "      data,target = data.cuda(),target.cuda()\n",
        "    data.target = Variable(data,volatile),Variable(target)\n",
        "    # training phase에 그레디언트값을 0으로 초기화\n",
        "    if phase == 'training':\n",
        "      optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    # batch 사이즈마다 loss 를 구한다.\n",
        "    loss = F.nll_loss(output,target)\n",
        "    \n",
        "    # loss를 구해서 running_loss에 더해준다.\n",
        "    # running은 배치 사이즈마다 갱신이 된다.\n",
        "    running_loss += F.nll_loss(output, target,size_average = False).data\n",
        "    # 학습을 통해 예측을 한다.\n",
        "    preds = output.data.max(dim = 1, keepdim = True)[1]\n",
        "    # 예측을 한 값과 비교하여 맞을 경우 더해준다.\n",
        "    running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "\n",
        "    if phase == 'training':\n",
        "      # 역전파\n",
        "      loss.backward()\n",
        "      # 가중치 업데이트\n",
        "      optimizer.step()\n",
        "\n",
        "  loss = running_loss/len(data_loader.dataset)\n",
        "  accuracy = 100.*running_correct/len(data_loader.dataset)\n",
        "\n",
        "  print(f\"{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}\")  \n",
        "  return loss, accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAQ37bdYop1T",
        "colab_type": "code",
        "outputId": "94837edf-2de2-43f4-cd76-d0f3606c80ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        }
      },
      "source": [
        "train_losses, train_accuracy = [],[]\n",
        "val_losses, val_accuracy = [],[]\n",
        "# epoch를 19세대만큼 돌린다.\n",
        "for epoch in range(1,20):\n",
        "  epoch_loss, epoch_accuracy = fit(epoch, model, train_loader, phase = 'training')\n",
        "  val_epoch_loss, val_epoch_accuracy = fit(epoch,model,test_loader, phase='validation')\n",
        "  train_losses.append(epoch_loss)\n",
        "  train_accuracy.append(epoch_accuracy)\n",
        "  val_losses.append(val_epoch_loss)\n",
        "  val_accuracy.append(val_epoch_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss is  0.63 and training accuracy is 47958/60000     79.93\n",
            "validation loss is  0.16 and validation accuracy is 9524/10000     95.24\n",
            "training loss is  0.21 and training accuracy is 56408/60000     94.01\n",
            "validation loss is 0.092 and validation accuracy is 9714/10000     97.14\n",
            "training loss is  0.16 and training accuracy is 57245/60000     95.41\n",
            "validation loss is 0.078 and validation accuracy is 9762/10000     97.62\n",
            "training loss is  0.13 and training accuracy is 57662/60000      96.1\n",
            "validation loss is 0.068 and validation accuracy is 9787/10000     97.87\n",
            "training loss is  0.12 and training accuracy is 57867/60000     96.44\n",
            "validation loss is 0.062 and validation accuracy is 9803/10000     98.03\n",
            "training loss is  0.11 and training accuracy is 58110/60000     96.85\n",
            "validation loss is 0.053 and validation accuracy is 9834/10000     98.34\n",
            "training loss is   0.1 and training accuracy is 58220/60000     97.03\n",
            "validation loss is 0.054 and validation accuracy is 9837/10000     98.37\n",
            "training loss is 0.091 and training accuracy is 58419/60000     97.36\n",
            "validation loss is  0.05 and validation accuracy is 9844/10000     98.44\n",
            "training loss is 0.085 and training accuracy is 58491/60000     97.49\n",
            "validation loss is 0.046 and validation accuracy is 9848/10000     98.48\n",
            "training loss is 0.082 and training accuracy is 58559/60000      97.6\n",
            "validation loss is 0.041 and validation accuracy is 9872/10000     98.72\n",
            "training loss is 0.077 and training accuracy is 58615/60000     97.69\n",
            "validation loss is 0.039 and validation accuracy is 9866/10000     98.66\n",
            "training loss is 0.076 and training accuracy is 58651/60000     97.75\n",
            "validation loss is 0.042 and validation accuracy is 9866/10000     98.66\n",
            "training loss is 0.072 and training accuracy is 58699/60000     97.83\n",
            "validation loss is 0.036 and validation accuracy is 9875/10000     98.75\n",
            "training loss is 0.071 and training accuracy is 58700/60000     97.83\n",
            "validation loss is 0.035 and validation accuracy is 9880/10000      98.8\n",
            "training loss is 0.066 and training accuracy is 58805/60000     98.01\n",
            "validation loss is 0.032 and validation accuracy is 9891/10000     98.91\n",
            "training loss is 0.065 and training accuracy is 58843/60000     98.07\n",
            "validation loss is 0.035 and validation accuracy is 9886/10000     98.86\n",
            "training loss is 0.062 and training accuracy is 58885/60000     98.14\n",
            "validation loss is 0.033 and validation accuracy is 9887/10000     98.87\n",
            "training loss is 0.061 and training accuracy is 58887/60000     98.14\n",
            "validation loss is 0.035 and validation accuracy is 9887/10000     98.87\n",
            "training loss is 0.058 and training accuracy is 58966/60000     98.28\n",
            "validation loss is 0.032 and validation accuracy is 9894/10000     98.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SKQMGCrVKVk",
        "colab_type": "text"
      },
      "source": [
        "### 학습이 진행됨에 따라 training set & validation set 의 loss 값이 줄어드는 모습을 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyDDG4ofqH70",
        "colab_type": "code",
        "outputId": "26e3efe9-b547-40e6-b8f6-aaf67e708e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# training loss : blue\n",
        "plt.plot(range(1,len(train_losses)+1), train_losses, 'bo', label = 'training loss')\n",
        "# validation loss : red\n",
        "plt.plot(range(1,len(val_losses)+1), val_losses, 'r', label = \"validation loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f68b8027240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9xBfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkfOYJqhVaWx",
        "colab_type": "text"
      },
      "source": [
        "### 학습이 진행됨에 따라 training set & validation set 의 accuracy가 향상되는 모습을 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhhxWrhks8OE",
        "colab_type": "code",
        "outputId": "c7e7a6ed-3094-42c7-9329-e7867b6fc5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(range(1,len(train_accuracy)+1), train_accuracy, 'bo', label = 'training accuracy')\n",
        "plt.plot(range(1,len(val_accuracy)+1), val_accuracy, 'r', label = \"validation accuracy\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f68b8776390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYm4/w/ITCAE3fL11QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkbtpEk08UO_",
        "colab_type": "text"
      },
      "source": [
        "### [CNN] 다음 코드를 무엇을 의미하는지 이해하고 실행하여 결과를 확인하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmTC8FR_Y62",
        "colab_type": "text"
      },
      "source": [
        "##### 뉴럴 네트워크는 torch.nn 패키지를 이용하여 생성할 수 있다. \n",
        "##### autograd와 autograd를 이용하여 모델을 정의하고 미분을 수행하는 nn 패키지에 대하여 알았다. nn.Module은 여러개의 레이어와 output을 리턴하는 forward(input) 메서드를 포함한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgO-tskFABiB",
        "colab_type": "text"
      },
      "source": [
        "#### 일반적인 뉴럴 네터워크의 학습 절차는 다음과 같다.\n",
        "##### - 학습 가능한 파라미터나 weight가 있는 뉴럴 네트워크를 정의한다.\n",
        "##### - 입력 데이터셋에 대한 반복 학습을 진행한다.\n",
        "##### - 네트워크를 통해 입력 값을 처리한다.\n",
        "##### - loss를 계산한다.\n",
        "##### - 손실 계산 = 출력(output)과 정답(target)의 차이\n",
        "##### - 그레디언트를 네트워크의 파라미터로 역전파(backward) 시킨다.\n",
        "##### - 다음과 같이 간단한 갱신 룰을 이용하여 네트워크의 weight를 갱신한다.\n",
        "##### Weight = Weight - learning_rate * gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbcBDpcTtON8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.nn 패키지를 사용하여 신경망을 생성함.\n",
        "# nn 패키지는 모델을 정의할 때, autograd를 통해 자동미분 기능을 제공함\n",
        "# nn.Module은 층과 전방 전파 forward propagation(입력 -> 출력)을 쉽게 구현함\n",
        "# 참고로 nn 패키지는 mini-batch만 지원함, 예로 nnConv2d는 4차 Tensor를 받음(nSamples*nChannels*height*width))\n",
        "# 아래 AlexNet 예시는 숫자를 분류하는 간단한 컨볼루션 신경망의 예임\n",
        "# 예시는 사진 입력을 받고, 몇 개의 층에 전방 전파하면서 분류를 출력함\n",
        "# - 출력을 위해서 모델은 다음과 같은 학습을 수행함.\n",
        "# - 신경망은 학습가능한 매개변수(가중치들)들을 가짐\n",
        "# - 사진 데이터를 반복적으로 입력함\n",
        "# - 신경망을 통해 입력을 처리함 (전방 전파)\n",
        "# - 손실 (오차)를 계산함  - 실제 출력과 예측 출력을 비교하여 학습의 올바름을 판단함\n",
        "# - 오차로부터 그레디언트 (경사, 방향)을 신경망의 각 매개변수에게 역전파함 (오류 역전파)\n",
        "# - 신경망의 매개변수들을 갱신함 ((미래)가중치 = (현재)가중치 - 학습률 * 그래디언트 )\n",
        "\n",
        "# 위의 컨볼루션 신경망의 부분들을 torch를 통해서 손쉽게 구현할 수 있음.\n",
        "# 단지 forward 함수만 정의하면, autograd를 이용해 해당 연산 그래프의 그래디언트를 구하는 backward 자동적으로 정의됨\n",
        "# forward 함수는 Tensor를 이용할 수 있는 다양한 연산들을 사용하여 정의 가능함\n",
        "# torch.Tensor : 자동 미분 기능을 지원하는 다차원 배열, 각 Tensor에 해당하는 그래디언트를 가짐\n",
        "# nn.Module : 신경망 모듈이며 매개변수의 캡슐화, GPU 연산 등 작업을 쉽게 가능하게 함\n",
        "# nn.Parameter : 모듈이 지정되면 매개변수들을 자동으로 관리하는 Tensor의 하나임\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq70Hly_BCfe",
        "colab_type": "text"
      },
      "source": [
        "### 네트워크 정의(Define the Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-u_ZU5rDNhO",
        "colab_type": "text"
      },
      "source": [
        "###### 사용자는 직접 forward 함수만 정의해주면 된다. 그래디언트가 계산되는 backward 함수는 autograd를 사용함으로써 자동으로 정의 된다. 사용자는 forward 함수에서 모든 텐서 연산을 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLkOA_fIBJXt",
        "colab_type": "code",
        "outputId": "e60d0323-babc-4f86-d15e-dfce2c708889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    # an affine operation : y = Wx + b\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Max pooling over a (2,2) window\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    # If the size is a square you can only specify a single number\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self,x):\n",
        "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpXl-WNmDtEI",
        "colab_type": "text"
      },
      "source": [
        "#### (2) 정의된 컨볼루션 신경망의 구조 설명"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at15_8W2C920",
        "colab_type": "code",
        "outputId": "357571c8-8fb2-4e4b-db0d-fe59bec1a1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# net.parameters()를 사용하여 정의된 신경망의 학습가능한 매개변수들을 확인할 수 있음\n",
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's . weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBsyJhnUEP2d",
        "colab_type": "text"
      },
      "source": [
        "###### 32 x 32 크기의 랜덤 값을 입력으로 사용하면 다음과 같다. 참고로 이 네트워크(LeNet)에 대한 예상 입력 크기는 32 x 32 이다. 이 네트워크를 MNIST 데이터셋을 대상으로 사용하기 위해서는 데이터셋의 이미지를 32x32 크기로 변경할 필요가 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV21gGI4EJbz",
        "colab_type": "code",
        "outputId": "dffb1bff-7bb2-4355-ea0d-47d72f75bca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 다음의 임의의 32 x 32 입력을 가정함\n",
        "# 참고로 크기가 다른 입력을 받을 때는 입력의 크기를 재조정하거나 신경망을 수정함\n",
        "input = torch.randn(1,1,32,32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0458,  0.0531,  0.0565,  0.0112,  0.0038,  0.0271, -0.0748, -0.0935,\n",
            "         -0.0627,  0.0927]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TyymOsUEzu_",
        "colab_type": "text"
      },
      "source": [
        "###### 모든 파라미터의 그레디언트 버퍼를 0으로 설정하고, 랜덤 그레디언트로 역전파를 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zb4Q0rPEv8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 오류 역전파를 통해 그레디언트를 구하기 전에 모든 가중치의 그레디언트 버퍼들을 초기화\n",
        "net.zero_grad()\n",
        "out.backward(torch.randn(1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS_rvijdFH6P",
        "colab_type": "text"
      },
      "source": [
        "##### torch.nn 은 mini-batch만을 지원한다. 전체 torch.nn 패키지는 mini-batch 형태인 입력만을 지원하며, 단일 데이터는 입력으로 지원하지 않는다.\n",
        "\n",
        "##### 예를 들어 nn.Conv2d 는 nSamples x nChannels x Height x Width의 4차원 텐서를 취한다.\n",
        "\n",
        "##### 만약 단일 샘플이 있다면, input.unsqueeze(0) 을 사용하여 가짜 임시 배치 차원을 추가하면 된다.\n",
        "\n",
        "##### 좀 더 진행하기에 앞서, 지금까지 살펴본 것을 정리하면 다음과 같다.\n",
        "##### torch.Tensor - backward() 와 같은 autograd 연산을 지원하는 다차원 배열이며 텐서에 대한 그레디언트를 가지고 있다. \n",
        "##### nn.Module - 뉴럴 네트워크 모듈로서 파라미터를 GPU로 옮기거나, 내보내기, 불러오기 등의 보조 작업을 이용하여 파라미터를 캡슐화 하는 편리한 방법이다.\n",
        "##### autograd.Function - autograd 연산의 forward와 backward에 대한 정의를 구현한다. 모든 Tensor 연산은 최소한 하나의 Function 노드를 생성하는데, 이 노드는 Tensor를 생성하고 기록을 인코딩 하는 여러 함수들에 연결된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMo_jkmwbq3Q",
        "colab_type": "text"
      },
      "source": [
        "### 손실함수 ( Loss Function )\n",
        "###### 오차 함수는 (출력, 정답) 형태의 입력을 받아, 출력이 정답에서 얼마나 멀리 떨어져 있는지 추정하는 값을 계산한다.\n",
        "###### nn 패키지에는 여러 가지 손실 함수들이 존재하는데 가장 간단한 loss는 nn.MSELoss로 입력과 정답 사이의 평균 제곱오차를 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwam7-MvFEQh",
        "colab_type": "code",
        "outputId": "42e45ccc-3160-46a0-f955-27a0d7421873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 손실 함수 정의 및 임의의 값들에 대해서 오차 결과 확인\n",
        "# nn 패키지는 많이 사용되는 손실함수들을 제공하며, 해당 예제는 단순한 MSE를 사용\n",
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1,-1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7612, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9t4mdRufH1u",
        "colab_type": "text"
      },
      "source": [
        "### 역전파 ( Backpropagation )\n",
        "###### 에러를 역전파하기 위해 사용자는 loss.backward() 를 호출하면 된다. 다만 기존에는 그레디언트들을 초기화 할 필요가 있다. 그렇지 않으면 그레디언트들이 존재하는 그레디언트에 누적되어 저장되기 때문이다.\n",
        "\n",
        "####### loss.backward() 를 호출하고 backward 호출 이전과 이후의 conv1's의 바이어스 그레디언트를 살펴 볼 것이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcbITdUpccEL",
        "colab_type": "code",
        "outputId": "7921fbe1-0dd7-499c-8cfc-244b1d5fca87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 앞에 코드에서 언급한 것과 같이 오류 역전파하기 전, 그래디언트를 초기화해야 함\n",
        "# backward() 수행 후 어떤 변화가 있는지 확인하고, 초기화의 필요성을 확인함\n",
        "net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTwwrV9feu7M",
        "colab_type": "code",
        "outputId": "fa2d62d8-1c18-4f56-fed2-95f039fca420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad after backward\n",
            "tensor([ 0.0007, -0.0047,  0.0032,  0.0033, -0.0067, -0.0038])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKwqVeblfy9J",
        "colab_type": "text"
      },
      "source": [
        "### 가중치 갱신 ( Update the weights )\n",
        "###### 실제로 사용되는 가장 간단한 갱신 룰은 SGD이며 다음과 같은 식을 가진다.\n",
        "###### weight = weight - learning_rate * gradient\n",
        "\n",
        "##### 뉴럴 네트워크를 사용할 때 SGD, Nesterov-SGD, Adam, RMSProp 등과 같은 다양한 갱신 룰을 사용하고 싶을 수도 있다. 이러한 룰의 사용을 위해 PyTorch는 위와 같은 갱신 룰을 포함하는 torch.optim 패키지를 제공한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnoh3PlGe7_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SGD를 이용하여 가중치 갱신하는 코드는 다음과 같음\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data*learning_rate)\n",
        "\n",
        "# 하지만 위 구현 코드보다 실제, torch.optim에서 구현되는 SDG, Adam, RMSProp 등을 사용함\n",
        "# 오류 역전파에서 최적화하는 방법을 보인 예제 코드\n",
        "import torch.optim as optim\n",
        "\n",
        "#create optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
        "\n",
        "# in training loop:\n",
        "optimizer.zero_grad() # zero the gradient buffers\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()  # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hahq4fs62hvh",
        "colab_type": "text"
      },
      "source": [
        "## 3. [분류기 학습] 다음 코드를 무엇을 의미하는지 이해하고 실행하여 결과를 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY3G5Q1JhNum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1번의 기초적인 신경망을 통해서 사진 분류기를 학습함\n",
        "# 데이터집합은 CIFAR-10 이며, 아래의 예와 같이 10가지의 3 (R,G,B) 채널의 32 x 32 크기의 사진으로 구성됨.\n",
        "# CIFAR-10 과 같이 많이 사용되는 데이터 집합은 torchvision 패키지에서 제공한다.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQihjWHg3PhR",
        "colab_type": "text"
      },
      "source": [
        "##### pytorch 에서 torchvision 이라는 패키지가 있는데, 해당 패키지는 일반적으로 사용되는 Imagenet, CIFAR10, MINIST 등과 같은 데이터셋들에 대한 데이터 로더(torchvision.datasets)와 이미지용 데이터 변환기(torch.utils.data.DataLoader)를 제공한다.\n",
        "\n",
        "##### CIFAR -10 데이터셋은 비행기, 자동차, 새, 고양이, 사슴, 개, 개구리, 말, 배, 트럭 순서의 클래스들을 가지고 있다. CIFAR-10의 이미지들은 3x32x32 인데 다시 말해 픽셀 크기의 3채널 컬러 이미지이다.\n",
        "\n",
        "#### 이미지 분류기 학습\n",
        "######1. torchvision을 이용하여 CIFAR-10 의 학습(training), 평가(test) 데이터셋을 로드하여 정규화한다.\n",
        "###### 2. 컨볼류션 뉴럴 네트워크를 학습 시킨다.\n",
        "###### 3. 손실 함수를 정의한다.\n",
        "###### 4. 학습 데이터를 이용하여 네트워크를 학습 시킨다.\n",
        "###### 5. 평가 데이터셋을 이용하여 네트워크를 평가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn3Zt-Mm4aD-",
        "colab_type": "text"
      },
      "source": [
        "#1. CIFAR-10 로딩 및 정규화\n",
        "#### torchvision을 이용하면 CIFAR-10 로딩은 손쉬운 작업.\n",
        "#### torchvision 패키지의 출력은 [0,1] 범위의 PILImage 이다. 출력 데이터의 범위를 [-1,1]의 텐서로 정규화 한다,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6cAHFbL4KmX",
        "colab_type": "code",
        "outputId": "e532dad1-4a64-4667-a7bc-9dca35c26bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download = True, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 4, shuffle = False, num_workers = 2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsHTMmxO5dJ9",
        "colab_type": "code",
        "outputId": "6362a8d2-7a37-46a0-846d-ac1b2ea52697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# 훈련집합의 일부 사진들 확인\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "  img = img/2 + 0.5     # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "\n",
        "# got some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " deer   car  frog  ship\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONtbc1Ku8FF6",
        "colab_type": "text"
      },
      "source": [
        "## 2. 컨볼루션 뉴럴 네트워크 (합성곱 신경망) 정의\n",
        "#### 3채널 32 x 32 크기의 사진을 입력받고, 신경망을 통과해 10 부류를 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBvlZwOj7SNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    # input : 3   output : 6   kernel : 5x5\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    # pooling\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    # input : 6    output : 16    kernel : 5x5\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    # input : 16x5x5        output : 120\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    # input : 120          output : 84\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    # input : 84          output : 10\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "    \n",
        "  def forward(self,x) : \n",
        "    # conv1 -> relu -> pooling\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    # conv2 -> relu -> pool\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1,16*5*5)\n",
        "    # fc1 -> relu\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # fc2 -> relu\n",
        "    x = F.relu(self.fc2(x))\n",
        "    # fc3\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net =Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz2Ayxkm9ywg",
        "colab_type": "text"
      },
      "source": [
        "## 3. 손실 함수 및 Optimizer 정의\n",
        "#### 손실 함수는 Classification Cross-Entropy를 사용하고, optimizer는 momentum 을 세팅한 SGD를 이용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7JCSDXX9vn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXKYsqc9_tmY",
        "colab_type": "text"
      },
      "source": [
        "## 4. 네트워크 학습\n",
        "#### 단순히 데이터를 반복시켜 네트워크와 optimizer의 입력으로 넘겨준다.\n",
        "#### 훈련 집합을 이용하여 신경망을 학습시킴."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqXzZbvQ_rvp",
        "colab_type": "code",
        "outputId": "db5b1046-cd50-4826-dc7b-8e4b1b192344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "for epoch in range(2): \n",
        "  # loop over the dataset multiple times\n",
        "  running_loss = 0.0\n",
        "  \n",
        "  for i,data in enumerate(trainloader,0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if (i%2000 == 1999):\n",
        "      print('[%d, %5d] loss : %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss : 2.168\n",
            "[1,  4000] loss : 1.834\n",
            "[1,  6000] loss : 1.653\n",
            "[1,  8000] loss : 1.575\n",
            "[1, 10000] loss : 1.515\n",
            "[1, 12000] loss : 1.470\n",
            "[2,  2000] loss : 1.427\n",
            "[2,  4000] loss : 1.393\n",
            "[2,  6000] loss : 1.355\n",
            "[2,  8000] loss : 1.316\n",
            "[2, 10000] loss : 1.294\n",
            "[2, 12000] loss : 1.308\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFxdrIrEhSG",
        "colab_type": "text"
      },
      "source": [
        "### (3) 화면 출력 확인 및 학습이 되고 있는지 서술\n",
        "#### 위의 결과를 보면 두번의 epoch 를 돌면서 학습을 시켰다. 두 세대에서 모두 loss 값이 줄어드는 경황을 봤을 때, 학습이 되고 있다 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5eEOXSZE7p5",
        "colab_type": "text"
      },
      "source": [
        "## 5. 평가 데이터를 이용한 네트워크 평가\n",
        "#### 위의 학습에서 실제로 네트워크가 무엇인가를 배웠는지 대하여 테스트를 해야만 한다.\n",
        "#### 뉴럴 네트워크의 출력인 클래스 label을 예측하고 실제 데이터와 비교함으로써 테스트를 수행할 수 있는데 만약 예측 결과가 올바르다면 올바른 예측 리스트에 샘플을 추가할 수 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vxP-BUHBH18",
        "colab_type": "code",
        "outputId": "e406ad54-e0c0-45c4-8405-7b7277316c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# 5. 테스트 집합을 이용하여 신경망 성능 확인\n",
        "dataiter = iter(testloader)\n",
        "images,labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:    cat  ship  ship plane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxf8HV/T+BepgTjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh4QcQGRG1ej",
        "colab_type": "text"
      },
      "source": [
        "#### 학습된 네트워크로 예측하기\n",
        "#### 출력은 총 10개의 클래스\n",
        "#### 가장 높은 예측값을 가진 클래스를 선택해 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj3edm3dFt4g",
        "colab_type": "code",
        "outputId": "d55b77c4-4641-4fae-88d1-d8de266e3c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs,1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:    cat   car  ship  ship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5snaqHX7HI5m",
        "colab_type": "text"
      },
      "source": [
        "#### 전체 데이터셋에 대한 네트워크의 학습 정확도 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9K-5jY2GnLP",
        "colab_type": "code",
        "outputId": "a06c78a9-90c0-4523-fdb4-dab1a4219d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# performance on the whole test dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100*correct/total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywXLNK9QIDcF",
        "colab_type": "text"
      },
      "source": [
        "### (6) 화면 출력 확인 및 일반화 성능 서술\n",
        "#### 53% 의 정확도가 나온것으로 보아하니, 총 10개의 클래스 중 한개를 선택하는 10% 보다는 확률이 높다. 따라서 네트워크가 무엇인가를 배웠다고 할 수 있다. \n",
        "#### 하지만 10개의 분류로 나누는데에 있어서 모델적인 한계가 있어 일반화를 시키기에는 성능이 떨어지는 모델이라고 볼 수 있다.\n",
        "#### 의문점을 가지고 epoch 를 20으로 바꿔 학습을 시켜보았으나 정확도는 55%로 2% 정도 오르는 현상을 발견 했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvof8ItPHzYH",
        "colab_type": "code",
        "outputId": "04a7f7d0-8b82-4b8e-b3ee-4868462fb9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images,labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs,1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Accuracy of %5s : %2d %%\" % (classes[i],100*class_correct[i]/class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 56 %\n",
            "Accuracy of   car : 55 %\n",
            "Accuracy of  bird : 36 %\n",
            "Accuracy of   cat : 30 %\n",
            "Accuracy of  deer : 54 %\n",
            "Accuracy of   dog : 63 %\n",
            "Accuracy of  frog : 46 %\n",
            "Accuracy of horse : 63 %\n",
            "Accuracy of  ship : 58 %\n",
            "Accuracy of truck : 68 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQPGQREK4eYe",
        "colab_type": "text"
      },
      "source": [
        "## (7) 화면 출력 확인 및 부류별 분류기의 성능 서술\n",
        "##### 대체적으로 서로 비슷한 특징을 가지고 있는 bird, cat, deer의 일반화 성능이 제일 좋지 못하고, plane, ship 같은 특징이 명확한 사진 같은 경우는 일반화 성능이 괜찮게 나오는것을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glNSbFYl45xk",
        "colab_type": "text"
      },
      "source": [
        "# 4. 컨볼루션 층의 입력 크기가 32x32x3 이고, \n",
        "##(a) 10개 5x5 필터들을 보폭 1과 덧대기 2로 적용하였을 때, 출력의 크기와 매개 변수의 수를 구하세요. \n",
        "### -> 5x5 filter의 depth는 입력의 depth와 동일하게 설정이 된다. 따라서 10개의 5x5x3 filter 10개를 보폭 1로 적용하였을 때, 30x30 이 되는데 여기서 2로 padding 작업을 해줘서 32x32 로 유지가 된다. 그래서 출력의 크기는 32x32x10 이다. 매개변수의 수는 5x5x10 이 된다.\n",
        "\n",
        "##(b) 동일한 입력에 64개 3*3 필터들을 보폭 1과 덧대기 1로 적용하였을 때 출력의 크기와 매개변수의 수도 구하세요.\n",
        "### -> 3x3 filter를 보폭 1과 덧대기 1로 적용할 때는 출력의 사이즈는 입력의 사이즈와 동일하다. 따라서 출력의 크기는 32x32x64 이고, 매개변수의 수는 3x3x64 개가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd97cD_b6ZdO",
        "colab_type": "text"
      },
      "source": [
        "# 5. 다음 조건을 만조가는 컨볼류션 신경망을 구현하고, 3번의 (3),(6),(7)의 성능 결과를 확인하고 비교하세요.\n",
        "### (1) INPUT-CONV(32 3X3) - CONV(32 3X3) - RELU-POOL-CONV(32 3X3) - CONV(32 3X3) - RELU - POOL - FC - OUTPUT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEERyqFz6vtV",
        "colab_type": "code",
        "outputId": "c5a862d8-7f7a-40dd-e2cf-5aa6db73990b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    # 신경망 정의\n",
        "    # input : 3 output : 32 kernel : 3x3\n",
        "    self.conv1 = nn.Conv2d(3,32,3)\n",
        "    # input : 32 output : 32 kernel : 3x3\n",
        "    self.conv2 = nn.Conv2d(32,32,3)\n",
        "    # input : 3 output : 32 kernel : 3x3\n",
        "    self.conv3 = nn.Conv2d(32,32,3)\n",
        "    # input : 3 output : 32 kernel : 3x3\n",
        "    self.conv4 = nn.Conv2d(32,32,3)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    # input : 32x5x5 output : 10\n",
        "    self.fc1 = nn.Linear(32*5*5,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # 신경망 구성\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.pool(F.relu(x))\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.pool(F.relu(x))\n",
        "    x = x.view(-1,32*5*5)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "#훈련 집합을 이용하여 신경망을 학습시킴\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.980\n",
            "[1,  4000] loss: 1.559\n",
            "[1,  6000] loss: 1.440\n",
            "[1,  8000] loss: 1.340\n",
            "[1, 10000] loss: 1.267\n",
            "[1, 12000] loss: 1.191\n",
            "[2,  2000] loss: 1.124\n",
            "[2,  4000] loss: 1.106\n",
            "[2,  6000] loss: 1.088\n",
            "[2,  8000] loss: 1.067\n",
            "[2, 10000] loss: 1.047\n",
            "[2, 12000] loss: 1.050\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 65 %\n",
            "Accuracy of plane : 74 %\n",
            "Accuracy of   car : 76 %\n",
            "Accuracy of  bird : 44 %\n",
            "Accuracy of   cat : 55 %\n",
            "Accuracy of  deer : 64 %\n",
            "Accuracy of   dog : 61 %\n",
            "Accuracy of  frog : 66 %\n",
            "Accuracy of horse : 66 %\n",
            "Accuracy of  ship : 68 %\n",
            "Accuracy of truck : 79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn1HcoldeJR3",
        "colab_type": "text"
      },
      "source": [
        "### (1-분석) 3번과 다른 신경망을 구축하여 학습을 시킨 결과 65% 의 정확도을 얻게 되었다. 이는 이전 신경망의  정확도보다 대략 8~10% 높아진 결과로 봤을때 이 분류기에 조금 더 최적화된 네트워크라고 할 수 있겠다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg4jq2joHVtw",
        "colab_type": "text"
      },
      "source": [
        "### (2) 3번 문제의 신경망에 Adam 최적화 ( 강의자료의 기본 hyper-parameters 사용 ) 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cvEbb_Y2zZ4",
        "colab_type": "code",
        "outputId": "364e1179-3675-4f87-ddf1-a4ba160bc6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "#5-2번\n",
        "#3번의 3에 해당\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # input : 3 output : 6 kernel : 5x5\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5) \n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    # input : 6 output : 16 kernel : 5x5\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    # input : 16x5x5 output : 120\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    # input : 120 output : 84\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    # input : 84 output : 10\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Pooling\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5) \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "### 4. 훈련집합을 이용하여 신경망을 학습시킴\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.864\n",
            "[1,  4000] loss: 1.612\n",
            "[1,  6000] loss: 1.530\n",
            "[1,  8000] loss: 1.468\n",
            "[1, 10000] loss: 1.422\n",
            "[1, 12000] loss: 1.397\n",
            "[2,  2000] loss: 1.326\n",
            "[2,  4000] loss: 1.293\n",
            "[2,  6000] loss: 1.320\n",
            "[2,  8000] loss: 1.287\n",
            "[2, 10000] loss: 1.287\n",
            "[2, 12000] loss: 1.294\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 53 %\n",
            "Accuracy of plane : 39 %\n",
            "Accuracy of   car : 62 %\n",
            "Accuracy of  bird : 22 %\n",
            "Accuracy of   cat : 50 %\n",
            "Accuracy of  deer : 50 %\n",
            "Accuracy of   dog : 33 %\n",
            "Accuracy of  frog : 70 %\n",
            "Accuracy of horse : 58 %\n",
            "Accuracy of  ship : 79 %\n",
            "Accuracy of truck : 64 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K63Ijlw-ef_P",
        "colab_type": "text"
      },
      "source": [
        "###(2-분석) SGD 방식에서 Adam 방식으로 최적화 방법을 바꾼 결과를 봤을때 단순 정확도만 봤을때는 거의 차의가 없는 것으로 보인다. 따라서 신경망 모델의 구조가 달라지지 않는 이상, 최적화 방법은 큰 영향을 끼치지 않는것으로 보인다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkYGEtaYIAFz",
        "colab_type": "text"
      },
      "source": [
        "### (3) 데이터 확대 방법들 중 하나를 적용한 후, 3번 문제의 신경망 학습 (Hint : transforms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLaUMxfIHVR",
        "colab_type": "code",
        "outputId": "bf7fb75c-630b-4f0e-e6b3-3e2b07597223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "#5-3\n",
        "# Data transform\n",
        "transform_3 = transforms.Compose([transforms.RandomRotation(10),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset_3 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_3)\n",
        "test_dataset_3 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_3)\n",
        "\n",
        "trainloader_3 = torch.utils.data.DataLoader(train_dataset_3, batch_size = 4, shuffle = True, num_workers = 2)\n",
        "testloader_3 = torch.utils.data.DataLoader(test_dataset_3, batch_size = 4, shuffle = False, num_workers = 2)\n",
        "\n",
        "net = Net()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader_3, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader_3:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader_3:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.266\n",
            "[1,  4000] loss: 1.951\n",
            "[1,  6000] loss: 1.742\n",
            "[1,  8000] loss: 1.649\n",
            "[1, 10000] loss: 1.571\n",
            "[1, 12000] loss: 1.512\n",
            "[2,  2000] loss: 1.451\n",
            "[2,  4000] loss: 1.424\n",
            "[2,  6000] loss: 1.382\n",
            "[2,  8000] loss: 1.343\n",
            "[2, 10000] loss: 1.335\n",
            "[2, 12000] loss: 1.318\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 52 %\n",
            "Accuracy of plane : 69 %\n",
            "Accuracy of   car : 80 %\n",
            "Accuracy of  bird : 27 %\n",
            "Accuracy of   cat : 19 %\n",
            "Accuracy of  deer : 53 %\n",
            "Accuracy of   dog : 38 %\n",
            "Accuracy of  frog : 70 %\n",
            "Accuracy of horse : 54 %\n",
            "Accuracy of  ship : 58 %\n",
            "Accuracy of truck : 54 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLoiuMw_bKvX",
        "colab_type": "text"
      },
      "source": [
        "### (3 - 분석) 데이터 transform 을 진행한 후 학습을 하였으나 5-2 의 accuracy 와 비교 했을때 1% 정도 떨어짐을 볼 수 있었다. 제한된 모델로는 한계가 있는것으로 보인다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahh1c5T7IV36",
        "colab_type": "text"
      },
      "source": [
        "### (4) 3번 문제의 신경망에 CONV 층마다 배치 정규화를 적용 (HINT : nn.BatchNorm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeZ2THmtIhnp",
        "colab_type": "code",
        "outputId": "9ad33003-5cbe-4e3c-c262-625d6aa901aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "#5-4번\n",
        "class Net_4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net_4, self).__init__()\n",
        "    # input : 3 output : 6 kernel : 5x5\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    # input : 6 output : 16 kernel : 5x5\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    # input : 16x5x5 output : 120\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    # input : 120 output : 84\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    # input 84 output : 10\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "    \n",
        "    # BatchNorm 사용\n",
        "    self.layer1 = nn.Sequential(self.conv1,\n",
        "                                nn.BatchNorm2d(6),\n",
        "                                nn.ReLU(),\n",
        "                                self.pool)\n",
        "     # BatchNorm 사용\n",
        "    self.layer2 = nn.Sequential(self.conv2,\n",
        "                                nn.BatchNorm2d(16),\n",
        "                                nn.ReLU(),\n",
        "                                self.pool)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net_4 = Net_4()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_4.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net_4(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net_4(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net_4(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.975\n",
            "[1,  4000] loss: 1.708\n",
            "[1,  6000] loss: 1.588\n",
            "[1,  8000] loss: 1.537\n",
            "[1, 10000] loss: 1.504\n",
            "[1, 12000] loss: 1.455\n",
            "[2,  2000] loss: 1.386\n",
            "[2,  4000] loss: 1.378\n",
            "[2,  6000] loss: 1.354\n",
            "[2,  8000] loss: 1.349\n",
            "[2, 10000] loss: 1.302\n",
            "[2, 12000] loss: 1.291\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 54 %\n",
            "Accuracy of plane : 60 %\n",
            "Accuracy of   car : 75 %\n",
            "Accuracy of  bird : 34 %\n",
            "Accuracy of   cat : 18 %\n",
            "Accuracy of  deer : 50 %\n",
            "Accuracy of   dog : 60 %\n",
            "Accuracy of  frog : 67 %\n",
            "Accuracy of horse : 60 %\n",
            "Accuracy of  ship : 68 %\n",
            "Accuracy of truck : 48 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH4u9kjZezXF",
        "colab_type": "text"
      },
      "source": [
        "### (4-분석) 각 convolution 층 마다 batchnormalize 를 해줬으나 정확도에서는 크게 변동된 부분이 없다. 살짝 좋아진 부분은 있으나 큰 변동은 없는 것으로 보아 다른 규제 기법을 좀 더 찾아보는게 좋을듯 하다.\n",
        "### 학습을 새로 돌릴때마다 정확도가 좋아질때가 있고, 나빠질때도 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfYjV7TiIh77",
        "colab_type": "text"
      },
      "source": [
        "### (5) 3번 문제의 신경망에 로그우도 손실함수를 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwNbHjkZIlo9",
        "colab_type": "code",
        "outputId": "c6513f00-48ec-409d-9f5c-0aba5b9c4b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "#5-5번\n",
        "\n",
        "net = Net()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# log 우도 손실함수 적용\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net(inputs)\n",
        "    outputs = nn.LogSoftmax(dim=1)(outputs) \n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.179\n",
            "[1,  4000] loss: 1.853\n",
            "[1,  6000] loss: 1.680\n",
            "[1,  8000] loss: 1.606\n",
            "[1, 10000] loss: 1.516\n",
            "[1, 12000] loss: 1.449\n",
            "[2,  2000] loss: 1.417\n",
            "[2,  4000] loss: 1.366\n",
            "[2,  6000] loss: 1.347\n",
            "[2,  8000] loss: 1.343\n",
            "[2, 10000] loss: 1.313\n",
            "[2, 12000] loss: 1.289\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 53 %\n",
            "Accuracy of plane : 58 %\n",
            "Accuracy of   car : 61 %\n",
            "Accuracy of  bird : 25 %\n",
            "Accuracy of   cat : 17 %\n",
            "Accuracy of  deer : 35 %\n",
            "Accuracy of   dog : 64 %\n",
            "Accuracy of  frog : 76 %\n",
            "Accuracy of horse : 59 %\n",
            "Accuracy of  ship : 61 %\n",
            "Accuracy of truck : 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjDsBnZYfP5Q",
        "colab_type": "text"
      },
      "source": [
        "### (5 - 분석) 로그 우도 손실함수를 사용 함으로써 underfitting 을 줄일 수 있으나 정확도 면에서는 생각보다 많은 부분이 변동되지 않았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YPe8Ft7ImXa",
        "colab_type": "text"
      },
      "source": [
        "###(6) 3번 문제의 신경망에 L2놈 규제 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xD3kj3IpMD",
        "colab_type": "code",
        "outputId": "44e17e4d-45ee-4b8d-ee3c-1e16a70874e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "#5-6번\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net_6(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net_6, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(F.normalize(self.conv1(x), p = 2, eps=1e-12)))\n",
        "    x = self.pool(F.relu(F.normalize(self.conv2(x), p = 2, eps=1e-12)))\n",
        "    x = x.view(-1, 16 * 5 * 5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "    \n",
        "\n",
        "net_6 = Net_6()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# weight decay = 0.01 를 써서 L2 Norm 적용\n",
        "optimizer = optim.SGD(net_6.parameters(), lr=0.001, momentum=0.9, weight_decay = 0.01)\n",
        "\n",
        "for epoch in range(2): #loop over the dataset multiple times\n",
        "\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #forward + backward + optimize\n",
        "    outputs = net_6(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "            (epoch + 1, i + 1, running_loss/2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net_6(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "  # performance on each class\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net_6(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    c = (predicted == labels).squeeze()\n",
        "    for i in range(4):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += c[i].item()\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2d %%' % (\n",
        "      classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.158\n",
            "[1,  4000] loss: 1.911\n",
            "[1,  6000] loss: 1.803\n",
            "[1,  8000] loss: 1.721\n",
            "[1, 10000] loss: 1.668\n",
            "[1, 12000] loss: 1.598\n",
            "[2,  2000] loss: 1.572\n",
            "[2,  4000] loss: 1.554\n",
            "[2,  6000] loss: 1.549\n",
            "[2,  8000] loss: 1.516\n",
            "[2, 10000] loss: 1.501\n",
            "[2, 12000] loss: 1.488\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 41 %\n",
            "Accuracy of plane : 55 %\n",
            "Accuracy of   car :  5 %\n",
            "Accuracy of  bird : 18 %\n",
            "Accuracy of   cat : 34 %\n",
            "Accuracy of  deer : 27 %\n",
            "Accuracy of   dog : 47 %\n",
            "Accuracy of  frog : 35 %\n",
            "Accuracy of horse : 75 %\n",
            "Accuracy of  ship : 34 %\n",
            "Accuracy of truck : 79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXstTLsDfsOn",
        "colab_type": "text"
      },
      "source": [
        "###(6-분석) L2 norm 가중치 규제를 통하여 모델을 좀 더 general 하게 만들어줬지만, 정확도가 41% 까지 떨어지는 현상을 발견했다. 따라서 규제를 잘 이해하지 못하고 사용하는 경우 정확도에서 큰 손실을 볼 수 있을것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuAFWJ-fIqvV",
        "colab_type": "text"
      },
      "source": [
        "# 5. 신경망의 출력이 (0.4, 2.0, 0.001, 0.32)T 일때 소프트맥스 함수를 적용한 결과를 쓰시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4jQMo3Iyp-",
        "colab_type": "code",
        "outputId": "6969ee0c-9989-456a-d8f9-a5bd72912a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.Tensor([0.4,2.0,0.001,0.32])\n",
        "x = torch.t(x)\n",
        "\n",
        "m = torch.nn.Softmax()\n",
        "x = m(x)\n",
        "\n",
        "print(\"result : \", x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result :  tensor([0.1325, 0.6563, 0.0889, 0.1223])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzGIXuPAIzaO",
        "colab_type": "text"
      },
      "source": [
        "# 6. 소프트맥스 함수를 적용한 후 출력이 (0.001,0.9, 0.001, 0.098)T이고 레이블 정보가 (0,0,0,1)T 일 때, 세 가지 목적함수, 평균 제곱 오차, 교차 엔트로피, 로그우도를 계산하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jbf8WU0I_su",
        "colab_type": "code",
        "outputId": "5d980ed8-6b83-48e8-dad2-ce92f2491aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "output = torch.tensor([0.001, 0.9, 0.001, 0.098])\n",
        "label = torch.tensor([0,0,0,1.0])\n",
        "\n",
        "# 평균 제곱 오차\n",
        "mse = nn.MSELoss()\n",
        "mse_loss = mse(output,label)\n",
        "print(\"Result of MSE : \", mse_loss)\n",
        "\n",
        "# 교차 엔트로피\n",
        "cross_entropy_loss = -1*(label*(output.log2())).sum()\n",
        "print(\"Result of Cross Entropy Loss : \", cross_entropy_loss)\n",
        "\n",
        "# 로그우도\n",
        "log_likelihood_loss = (label*output).sum().log2()*-1\n",
        "print(\"Result of Log Likeli Hood Loss : \", log_likelihood_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result of MSE :  tensor(0.4059)\n",
            "Result of Cross Entropy Loss :  tensor(3.3511)\n",
            "Result of Log Likeli Hood Loss :  tensor(3.3511)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y44FyeAYKXWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}